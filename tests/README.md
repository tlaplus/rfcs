This is a large collection of test cases intended for adaptation by all relevant TLA⁺ tools.
While other parts of this repository specify how TLA⁺ tooling should work in the abstract, this part comes from the other direction and provides concrete inputs along with their expected outputs.
Currently, the sets of tests that have been developed include:
* Tests for TLA⁺ syntax parsing, in `tlaplus_syntax`
* Tests for TLA⁺ semantic validation like identifier resolution & level-checking, in `tlaplus_semantics`
* Tests for TLA⁺ semantic error handling, in `tlaplus_semantic_errors`

Each corpus has a README file containing information on how to apply it.

